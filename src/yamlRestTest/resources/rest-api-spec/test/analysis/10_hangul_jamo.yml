---
"hangul_jamo 한글 음절을 자모로 분해한다":
  - do:
      indices.analyze:
        body:
          text: "이재국"
          tokenizer: standard
          filter:
            - type: hangul_jamo
  - length: { tokens: 1 }
  - match:  { tokens.0.token: "ㅇㅣㅈㅐㄱㅜㄱ" }

---
"hangul_jamo 비한글 텍스트는 그대로 통과한다":
  - do:
      indices.analyze:
        body:
          text: "hello"
          tokenizer: standard
          filter:
            - type: hangul_jamo
  - length: { tokens: 1 }
  - match:  { tokens.0.token: "hello" }

---
"hangul_jamo 한글과 영문이 섞인 텍스트를 처리한다":
  - do:
      indices.analyze:
        body:
          text: "테스트abc"
          tokenizer: standard
          filter:
            - type: hangul_jamo
  - length: { tokens: 1 }
  - match:  { tokens.0.token: "ㅌㅔㅅㅡㅌㅡabc" }

---
"hangul_jamo 공백 기준으로 토큰을 분리하여 각각 자모 분해한다":
  - do:
      indices.analyze:
        body:
          text: "아디다스 운동화"
          tokenizer: standard
          filter:
            - type: hangul_jamo
  - length: { tokens: 2 }
  - match:  { tokens.0.token: "ㅇㅏㄷㅣㄷㅏㅅㅡ" }
  - match:  { tokens.1.token: "ㅇㅜㄴㄷㅗㅇㅎㅘ" }
